{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC 4 data - dataset construction inputevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from GRU-ODE-Bayes preprocessing; simplified and adapted for MIMIC 4 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_3 = pd.read_csv(\"/path/processed/admissions_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only choose previously selected admission ids\n",
    "inputs=pd.read_csv('/path/icu/inputevents.csv.gz')\n",
    "adm_ids=list(adm_3[\"hadm_id\"])\n",
    "inputs=inputs.loc[inputs[\"hadm_id\"].isin(adm_ids)]\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep columns of interest\n",
    "inputs_small=inputs[[\"subject_id\",\"hadm_id\",\"starttime\",\"endtime\",\"itemid\",\"amount\",\"amountuom\",\"rate\",\"rateuom\",\"patientweight\",\"ordercategorydescription\"]]\n",
    "print(\"Number of patients remaining in the database: \")\n",
    "print(inputs_small[\"subject_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get item ids for inputs \n",
    "item_id=pd.read_csv('/path/icu/d_items.csv.gz')\n",
    "item_id_1=item_id[[\"itemid\",\"label\"]]\n",
    "item_id_1.head()\n",
    "\n",
    "inputs_small_2=pd.merge(inputs_small,item_id_1,on=\"itemid\")\n",
    "inputs_small_2.head()\n",
    "print(\"Number of patients remaining in the database: \")\n",
    "print(inputs_small_2[\"subject_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each item, evaluate the number of patients who have been given this item\n",
    "# Select only the inputs with highest occurence\n",
    "pat_for_item=inputs_small_2.groupby(\"label\")[\"subject_id\"].nunique()\n",
    "frequent_labels=pat_for_item.sort_values(ascending=False)[:50]\n",
    "inputs_small_3=inputs_small_2.loc[inputs_small_2[\"label\"].isin(list(frequent_labels.index))].copy()\n",
    "\n",
    "print(\"Number of patients remaining in the database: \")\n",
    "print(inputs_small_3[\"subject_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(inputs_small_3.groupby(\"label\")[\"amountuom\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cleaning the Cefazolin (remove the ones that are not in dose unit)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"itemid\"]==225850) & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Cefepime (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Cefepime\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Ceftriaxone (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Ceftriaxone\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Ciprofloxacin (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Ciprofloxacin\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Famotidine (Pepcid) (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Famotidine (Pepcid)\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Fentanyl (Concentrate) (remove the non mg)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Fentanyl (Concentrate)\") & (inputs_small_3[\"amountuom\"]!=\"mg\")].index).copy()\n",
    "inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Fentanyl (Concentrate)\") & (inputs_small_3[\"amountuom\"]==\"mg\"),\"amount\"]*=1000\n",
    "inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Fentanyl (Concentrate)\") & (inputs_small_3[\"amountuom\"]==\"mg\"),\"amountuom\"]=\"mcg\"\n",
    "#Cleaning the Heparin Sodium (Prophylaxis) (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Heparin Sodium (Prophylaxis)\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Hydromorphone (Dilaudid) (remove the non mg)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Hydromorphone (Dilaudid)\") & (inputs_small_3[\"amountuom\"]!=\"mg\")].index).copy()\n",
    "#Cleaning the Magnesium Sulfate (remove the non grams)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Magnesium Sulfate\") & (inputs_small_3[\"amountuom\"]!=\"grams\")].index).copy()\n",
    "#Cleaning the Propofol (remove the non mg)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Propofol\") & (inputs_small_3[\"amountuom\"]!=\"mg\")].index).copy()\n",
    "#Cleaning the Metoprolol (remove the non mg)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Metoprolol\") & (inputs_small_3[\"amountuom\"]!=\"mg\")].index).copy()\n",
    "#Cleaning the Piperacillin/Tazobactam (Zosyn) (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Piperacillin/Tazobactam (Zosyn)\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Metronidazole (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Metronidazole\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Ranitidine (Prophylaxis)(remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Ranitidine (Prophylaxis)\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Vancomycin (remove the non dose)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Vancomycin\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()\n",
    "#Cleaning the Fentanyl. Put the mg to mcg \n",
    "inputs_small_3.loc[(inputs_small_3[\"itemid\"]==221744) & (inputs_small_3[\"amountuom\"]==\"mg\"),\"amount\"]*=1000\n",
    "inputs_small_3.loc[(inputs_small_3[\"itemid\"]==221744) & (inputs_small_3[\"amountuom\"]==\"mg\"),\"amountuom\"]=\"mcg\"\n",
    "#Cleaning of the Pantoprazole (Protonix)\n",
    "    #divide in two (drug shot or continuous treatment and create a new item id for the continuous version)\n",
    "inputs_small_3.loc[(inputs_small_3[\"itemid\"]==225910) & (inputs_small_3[\"ordercategorydescription\"]==\"Continuous Med\"),\"label\"]=\"Pantoprazole (Protonix) Continuous\"\n",
    "inputs_small_3.loc[(inputs_small_3[\"itemid\"]==225910) & (inputs_small_3[\"ordercategorydescription\"]==\"Continuous Med\"),\"itemid\"]=2217441\n",
    "#remove the non dose from the drug shot version\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Pantoprazole (Protonix)\") & (inputs_small_3[\"amountuom\"]!=\"dose\")].index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Preprocessing for MIMIC 4 items\n",
    "#Cleaning the Acetaminophen-IV (keep mg)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Acetaminophen-IV\") & (inputs_small_3[\"amountuom\"]!=\"mg\")].index).copy()\n",
    "\n",
    "#Cleaning the D5 1/2NS (keep ml)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"D5 1/2NS\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n",
    "#Cleaning the Dexmedetomidine (Precedex) (cast all to mg)\n",
    "inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Dexmedetomidine (Precedex)\") & (inputs_small_3[\"amountuom\"]==\"mcg\"),\"amount\"]/=1000\n",
    "inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Dexmedetomidine (Precedex)\") & (inputs_small_3[\"amountuom\"]==\"mcg\"),\"amountuom\"]=\"mg\"\n",
    "\n",
    "#Cleaning the LR\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"LR\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n",
    "#Cleaning the NaCl 0.9%\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"NaCl 0.9%\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n",
    "#Cleaning the OR Crystalloid Intake \n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"OR Crystalloid Intake\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n",
    "#Cleaning the PO Intake\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"PO Intake\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n",
    "#Cleaning the Pre-Admission/Non-ICU Intake \n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Pre-Admission/Non-ICU Intake\") & (inputs_small_3[\"amountuom\"]!=\"ml\")].index).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(inputs_small_3.groupby(\"label\")[\"amountuom\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for inputs given in rates\n",
    "inputs_small_3.groupby(\"label\")[\"rateuom\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning of Dextrose 5%  (remove the non mL/hour)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Dextrose 5%\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "#Cleaning of Magnesium Sulfate (Bolus)  (remove the non mL/hour)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Magnesium Sulfate (Bolus)\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "#Cleaning of NaCl 0.9% (remove the non mL/hour)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"NaCl 0.9%\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "#Cleaning of Piggyback (remove the non mL/hour)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Piggyback\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "#Cleaning of Packed Red Bllod Cells (remove the non mL/hour)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Packed Red Blood Cells\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "\n",
    "# additional cleaning for mimic4\n",
    "#Cleaning of Acetaminophen-IV\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Acetaminophen-IV\") & (inputs_small_3[\"rateuom\"]!=\"mg/min\")].index).copy()\n",
    "\n",
    "#Cleaning of Fentanyl (Concentrate)\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Fentanyl (Concentrate)\") & (inputs_small_3[\"rateuom\"]!=\"mcg/hour\")].index).copy()\n",
    "\n",
    "#Cleaning of Phenylephrine\n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Phenylephrine\") & (inputs_small_3[\"rateuom\"]!=\"mcg/kg/min\")].index).copy()\n",
    "\n",
    "#Cleaning of Sterile Water \n",
    "inputs_small_3=inputs_small_3.drop(inputs_small_3.loc[(inputs_small_3[\"label\"]==\"Sterile Water\") & (inputs_small_3[\"rateuom\"]!=\"mL/hour\")].index).copy()\n",
    "\n",
    "\n",
    "#Check if a single unit per drug\n",
    "inputs_small_3.groupby(\"label\")[\"rateuom\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the entries which are spread in time.\n",
    "We chose the duration window for the sampling. here we choose 30 minutes. So every entry which has a rate and with duration larger than 1 hour, we split it into fixed times injections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now split the entries which are spread in time. We chose the duration window for the sampling. here we choose 30 minutes. \n",
    "# So every entry which has a rate and with duration larger than 1 hour, we split it into fixed times injections.\n",
    "\n",
    "#First check the /hours units\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mcg/kg/hour\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/3600)*df_temp[\"patientweight\"]\n",
    "\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-1000*df_temp[\"amount\"])>0.01)].index)==0) #OK\n",
    "\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mL/hour\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/3600)\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-df_temp[\"amount\"])>0.01)].index)==0) #OK\n",
    "\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mg/hour\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/3600)\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-df_temp[\"amount\"])>0.01)].index)==0) #OK\n",
    "\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mcg/hour\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/3600)\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-df_temp[\"amount\"])>0.01)].index)==0) #OK\n",
    "\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"units/hour\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/3600)\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-df_temp[\"amount\"])>0.01)].index)==0) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mg/min\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/60)\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]-df_temp[\"amount\"])>0.01)].index)==0) #OK\n",
    "\n",
    "#Third check the kg/min units\n",
    "df_temp=inputs_small_3.loc[(inputs_small_3[\"rate\"].notnull()) & (inputs_small_3[\"rateuom\"].str.contains(\"mcg/kg/min\"))].copy()\n",
    "df_temp[\"computed_amount\"]=df_temp[\"rate\"]*((pd.to_datetime(df_temp[\"endtime\"])-pd.to_datetime(df_temp[\"starttime\"])).dt.total_seconds()/60)*df_temp[\"patientweight\"]\n",
    "\n",
    "#Check with a 0.01 tolerance\n",
    "assert(len(df_temp.loc[(abs(df_temp[\"computed_amount\"]/1000-df_temp[\"amount\"])>0.01)].index)==0) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_split_hours=0.5\n",
    "to_sec_fact=3600*duration_split_hours\n",
    "\n",
    "#split data set in four.\n",
    "\n",
    "#The first dataframe contains the entries with no rate but with extended duration inputs (over 0.5 hour)\n",
    "df_temp1=inputs_small_3.loc[((pd.to_datetime(inputs_small_3[\"endtime\"])-pd.to_datetime(inputs_small_3[\"starttime\"]))>timedelta(hours=duration_split_hours)) & (inputs_small_3[\"rate\"].isnull())].copy().reset_index(drop=True)\n",
    "#The second dataframe contains the entries with no rate and low duration entries (<0.5hour)\n",
    "df_temp2=inputs_small_3.loc[((pd.to_datetime(inputs_small_3[\"endtime\"])-pd.to_datetime(inputs_small_3[\"starttime\"]))<=timedelta(hours=duration_split_hours)) & (inputs_small_3[\"rate\"].isnull())].copy().reset_index(drop=True)\n",
    "#The third dataframe contains the entries with a rate and extended duration inputs (over 0.5 hour)\n",
    "df_temp3=inputs_small_3.loc[((pd.to_datetime(inputs_small_3[\"endtime\"])-pd.to_datetime(inputs_small_3[\"starttime\"]))>timedelta(hours=duration_split_hours)) & (inputs_small_3[\"rate\"].notnull())].copy().reset_index(drop=True)\n",
    "#The forth dataframe contains the entries with a rate and low duration entries (< 0.5 hour)\n",
    "df_temp4=inputs_small_3.loc[((pd.to_datetime(inputs_small_3[\"endtime\"])-pd.to_datetime(inputs_small_3[\"starttime\"]))<=timedelta(hours=duration_split_hours)) & (inputs_small_3[\"rate\"].notnull())].copy().reset_index(drop=True)\n",
    "\n",
    "#Check if split is complete\n",
    "assert(len(df_temp1.index)+len(df_temp2.index)+len(df_temp3.index)+len(df_temp4.index)==len(inputs_small_3.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then process all of these dfs.\n",
    "#In the first one, we need to duplicate the entries according to their duration and then divide each entry by the number of duplicates\n",
    "\n",
    "#We duplicate the rows with the number bins for each injection\n",
    "df_temp1[\"Repeat\"]=np.ceil((pd.to_datetime(df_temp1[\"endtime\"])-pd.to_datetime(df_temp1[\"starttime\"])).dt.total_seconds()/to_sec_fact).astype(int)\n",
    "df_new1=df_temp1.reindex(df_temp1.index.repeat(df_temp1[\"Repeat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then create the admninistration time as a shifted version of the STARTTIME.\n",
    "df_new1[\"charttime\"]=df_new1.groupby(level=0)['starttime'].transform(lambda x: pd.date_range(start=x.iat[0],freq=str(60*duration_split_hours)+'min',periods=len(x)))\n",
    "#We divide each entry by the number of repeats\n",
    "df_new1[\"amount\"]=df_new1[\"amount\"]/df_new1[\"Repeat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the third one, we do the same\n",
    "#We duplicate the rows with the number bins for each injection\n",
    "df_temp3[\"Repeat\"]=np.ceil((pd.to_datetime(df_temp3[\"endtime\"])-pd.to_datetime(df_temp3[\"starttime\"])).dt.total_seconds()/to_sec_fact).astype(int)\n",
    "df_new3=df_temp3.reindex(df_temp3.index.repeat(df_temp3[\"Repeat\"]))\n",
    "#We then create the admninistration time as a shifted version of the STARTTIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new3[\"charttime\"]=df_new3.groupby(level=0)['starttime'].transform(lambda x: pd.date_range(start=x.iat[0],freq=str(60*duration_split_hours)+'min',periods=len(x)))\n",
    "#We divide each entry by the number of repeats\n",
    "df_new3[\"amount\"]=df_new3[\"amount\"]/df_new3[\"Repeat\"]\n",
    "\n",
    "df_temp2[\"charttime\"]=df_temp2[\"starttime\"]\n",
    "df_temp4[\"charttime\"]=df_temp4[\"starttime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eventually, we merge all 4splits into one.\n",
    "inputs_small_4=df_new1.append([df_temp2,df_new3,df_temp4])\n",
    "#The result is a dataset with discrete inputs for each treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_small_4.to_csv(\"/path/processed/inputs_processed.csv\")\n",
    "inputs_small_4[\"hadm_id\"].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
